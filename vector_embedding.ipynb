{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34c405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.12/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /opt/anaconda3/lib/python3.12/site-packages (from scipy) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "# word2vec google news 300 (R^300)\n",
    "!pip3 install gensim\n",
    "!pip3 install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36f82d",
   "metadata": {},
   "source": [
    "#### Patch gensim to avoid downgrading SciPy: Unable to import gensim properly because gensim is trying to import triu from scipy.linalg, but in the latest SciPy version, the function triu has been removed from scipy.linalg. Instead, we're supposed to use numpy.triu. This 'monkey-patch' isn't recommended in the long-term but for a demo, it is suitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cbb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch gensim to avoid downgrading SciPy\n",
    "# Unable to import gensim properly because gensim is\n",
    "# trying to import triu from scipy.linalg, but in the latest\n",
    "# SciPy version, the function triu has been removed from \n",
    "# scipy.linalg. Instead, we're supposed to use \n",
    "# numpy.triu.\n",
    "# This 'monkey-patch' isn't recommended in the long-term\n",
    "# but for a demo, it is suitable\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "scipy.linalg.triu = np.triu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac5eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "# Pre-trained model for learning purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33f824",
   "metadata": {},
   "source": [
    "#### Example of a word as a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7c7337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
      " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
      "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
      "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
      " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
      " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
      "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
      "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
      " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
      " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
      " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
      "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
      " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
      "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
      "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
      "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
      " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
      " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
      "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
      "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
      "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
      "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
      " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
      " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
      "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
      "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
      " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
      "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
      " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
      " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
      " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
      " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
      "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
      " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
      "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
      "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
      " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
      " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
      " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
      " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
      " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
      " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
      " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
      " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
      "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
      " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
      "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
      "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
      " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
      "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
      " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
      "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
      " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
      " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
      " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
      " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
      " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
      " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
      " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
      "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
      "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
      " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
      "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
      " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
      "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
      " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
      "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
      " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
      " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
      " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
      "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
      "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
      "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
      "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
      "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model\n",
    "\n",
    "print(word_vectors['computer'])\n",
    "# R^300 vector for any word\n",
    "print(word_vectors['dog'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337c544",
   "metadata": {},
   "source": [
    "#### Similar Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914fee0",
   "metadata": {},
   "source": [
    "#### What would King + Woman - Man = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a18bf1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071), ('monarch', 0.6189674735069275), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.5181134343147278), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411403656006)]\n"
     ]
    }
   ],
   "source": [
    "# Ex of using most_similar\n",
    "print(word_vectors.most_similar(positive=['king', 'woman'],\n",
    "                                negative=['man'], topn=10))\n",
    "# What is the equivalent of a \"Woman King\" who is not a man?\n",
    "# A Queen right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124780db",
   "metadata": {},
   "source": [
    "#### Another example relating to sports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('basketball', 0.49093201756477356), ('hoops', 0.47231557965278625), ('shooters', 0.471876859664917), ('dribble', 0.4546862244606018), ('amuse_oneself', 0.4472128450870514), ('Slamball', 0.4436055123806), ('sports', 0.44302672147750854), ('baskeball', 0.4382047951221466), ('dunks_alley_oops', 0.4283624291419983), ('freethrow', 0.419028639793396)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['sport', 'hoop', 'shoot'],\n",
    "                                negative=['feet'], topn=10))\n",
    "# Sport that has a hoop and people shoot with \n",
    "# and they dont use their feet. Basketball!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57b55a",
   "metadata": {},
   "source": [
    "#### Check similarity between a few other pair of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de75e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76640123\n",
      "0.8543272\n",
      "0.7643474\n",
      "0.3779698\n",
      "0.22718486\n",
      "0.5318407\n",
      "0.086871386\n"
     ]
    }
   ],
   "source": [
    "# Ex: Calculating Similarity:\n",
    "print(word_vectors.similarity('woman', 'man'))\n",
    "print(word_vectors.similarity('boy', 'girl'))\n",
    "print(word_vectors.similarity('uncle', 'aunt'))\n",
    "print(word_vectors.similarity('plane', 'car'))\n",
    "print(word_vectors.similarity('hand', 'foot'))\n",
    "print(word_vectors.similarity('apple', 'banana'))\n",
    "print(word_vectors.similarity('wood', 'tennis'))\n",
    "\n",
    "# Notice wood and tennis have a very low similarity score\n",
    "# Whereas the rest of the pairs have a decent-strong similarity score\n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad032bd",
   "metadata": {},
   "source": [
    "#### Most similar words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3365befa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('towers', 0.8531749844551086), ('skyscraper', 0.6417425870895386), ('Tower', 0.639177143573761), ('spire', 0.5946877598762512), ('responded_Understood_Atlasjet', 0.5931612849235535)]\n"
     ]
    }
   ],
   "source": [
    "# Words most similar to tower\n",
    "print(word_vectors.most_similar(\"tower\", topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2278a4d",
   "metadata": {},
   "source": [
    "#### Now let's look at vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dbf2c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magnitude of the difference beteween man and woman is 1.7279510498046875\n",
      "The magnitude of the difference beteween plane and earthworm is 5.286352157592773\n",
      "The magnitude of the difference beteween aunt and uncle is 1.9634674787521362\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Words to compare:\n",
    "word1 = 'man'\n",
    "word2 = 'woman'\n",
    "\n",
    "word3 = 'plane'\n",
    "word4 = 'earthworm'\n",
    "\n",
    "word5 = 'aunt'\n",
    "word6 = 'uncle'\n",
    "\n",
    "# Calculate vector difference\n",
    "vec_diff_1 = model[word1] - model[word2]\n",
    "vec_diff_2 = model[word3] - model[word4]\n",
    "vec_diff_3 = model[word5] - model[word6]\n",
    "\n",
    "# Calculate the magnitude of the vector difference\n",
    "magn_of_diff1 = np.linalg.norm(vec_diff_1)\n",
    "magn_of_diff2 = np.linalg.norm(vec_diff_2)\n",
    "magn_of_diff3 = np.linalg.norm(vec_diff_3)\n",
    "\n",
    "print(f'The magnitude of the difference beteween {word1} and {word2} is {magn_of_diff1}')\n",
    "print(f'The magnitude of the difference beteween {word3} and {word4} is {magn_of_diff2}')\n",
    "print(f'The magnitude of the difference beteween {word5} and {word6} is {magn_of_diff3}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee9372",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
